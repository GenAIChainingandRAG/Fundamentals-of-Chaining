{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "631e33ca",
   "metadata": {},
   "source": [
    "![Multiple Chains](../assets/advanced-mutliple-chains.png)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694e2d22",
   "metadata": {},
   "source": [
    "### Learning objective:\n",
    "By the end of this lesson, you will be able to practice chaining and multiple chaining.\n",
    "\n",
    "\n",
    "### About:  \n",
    "In this lesson students will supercharge their workflows by processing documents in a model and creating multiple chains. \n",
    "\n",
    "\n",
    "### Prerequisites:\n",
    "- Python (required) \n",
    "- Intro to LangChain and prior prompt  eng. lessons (required) \n",
    "- Visual Studio Code (recommended)\n",
    "- GitHub Copilot lessons (recommended) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbfb2a1",
   "metadata": {},
   "source": [
    "### Contents\n",
    "1. [Imports](#imports)\n",
    "1. [LCEL chains](#lcel)\n",
    "1. [Multiple chains](#chains)\n",
    "\n",
    "### Activities\n",
    "1. [Lab](#lab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cc10da",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68385797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic chains\n",
    "from langchain_openai import ChatOpenAI #openai chatbot\n",
    "from langchain_core.prompts import ChatPromptTemplate #template for chat prompts\n",
    "from langchain_core.output_parsers import StrOutputParser #output parser for string output \n",
    "\n",
    "#documents \n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2c174",
   "metadata": {},
   "source": [
    "<a id='lcel'></a>\n",
    "## Chain Review \n",
    "**LCEL** allows you build complex chains with runnable components, \"runnables\" greatly reducing the amount of code you need to write for common model tasks. They come with common methods or interfaces that you can use in many situations. You quickly switch out components and create chains of chains (multiple chains). \n",
    "\n",
    "#### Basic Chain\n",
    "- Language or chat model \n",
    "- Prompt Template\n",
    "- Output parser\n",
    "\n",
    "\n",
    "## LCEL Chains\n",
    "In addition to custom chains you build, LangChain comes with a variety pre-built chains for common purposes you can use without having to specify each component. \n",
    "\n",
    "#### Example Pre-Built Chains\n",
    "- [create_stuff_documents_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html#langchain.chains.combine_documents.stuff.create_stuff_documents_chain): \"\tThis chain takes a list of documents and formats them all into a prompt, then passes that prompt to an LLM. It passes ALL documents, so you should make sure it fits within the context window the LLM you are using.\"\n",
    "- [load_query_constructor_runnable](https://api.python.langchain.com/en/latest/chains/langchain.chains.query_constructor.base.load_query_constructor_runnable.html#langchain.chains.query_constructor.base.load_query_constructor_runnable): \"Can be used to generates queries. You must specify a list of allowed operations, and then will return a runnable that converts a natural language query into those allowed operations.\"\n",
    "- [create_history_aware_retriever](https://api.python.langchain.com/en/latest/chains/langchain.chains.history_aware_retriever.create_history_aware_retriever.html#langchain.chains.history_aware_retriever.create_history_aware_retriever): \"This chain takes in conversation history and then uses that to generate a search query which is passed to the underlying retriever.\"\n",
    "- [and many more!](https://python.langchain.com/docs/modules/chains#lcel-chains)\n",
    "\n",
    "#### Key Interfaces\n",
    "- **Invoke (invoke):** Pass in a string and get back a string\n",
    "- **Stream (stream):** Streams the response \n",
    "- **Batch (batch):** Pass in multiple prompts and get back the response \n",
    "- **Async (ainvoke):** Run asynchronously \n",
    "\n",
    "#### Docs\n",
    "1. [LangChain LCEL](https://python.langchain.com/docs/expression_language/)\n",
    "1. [LangChain Interface](https://python.langchain.com/docs/expression_language/interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb86df47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sarah: Blue\\nJuana: Red'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example from LangChain docs (link above for create_stuff_documents_chain)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"What are everyone's favorite colors:\\n\\n{context}\")]\n",
    ")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# sample documents \n",
    "docs = [\n",
    "    Document(page_content=\"Sarah like blue but not green\"),\n",
    "    Document(page_content = \"Juana loves yellow but not as much as she loves red\")\n",
    "]\n",
    "\n",
    "chain.invoke({\"context\": docs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c0067",
   "metadata": {},
   "source": [
    "<a id='chains'></a>\n",
    "## Multiple chains\n",
    "Automate your work flows and build more complex systems by creating chains of chains. \n",
    "\n",
    "Generate a city and tourist destinations. \n",
    "\n",
    "![Prompt-Map](../assets/Additional%20Assets.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28246827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris, France is in the country of France.\\n\\nThree popular tourist destinations in France are:\\n1. The Eiffel Tower in Paris\\n2. The Palace of Versailles near Paris\\n3. The French Riviera, including cities like Nice and Cannes'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example \n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "#chain 1 prompt and chain to output a city\n",
    "prompt1 = ChatPromptTemplate.from_template(\"Name a popular city for tourists to visit in {month}.\")\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "#chain 2 prompt and chain- uses city from prompt 1 to generate destinations \n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"What country is the {city} in? Name 3 popular tourist destinations in that country.\"\n",
    ")\n",
    "chain2 = (\n",
    "    {\"city\": chain1} #include chain 1! \n",
    "    | prompt2\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain2.invoke({\"month\": \"August\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb6bc7f",
   "metadata": {},
   "source": [
    "<a id='trouble'></a>\n",
    "## Troubleshooting\n",
    "As we add more complexity to our chains, it will be important to see the mechanics behind LangChain to understand the results we are getting, to improve our prompts, and debug. \n",
    "\n",
    "- Review tools in LangChain (e.g., debug and verbose) to help track logs \n",
    "Demo each of debug and verbose \n",
    "\n",
    "#### Debug import and code: \n",
    "```python\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "```\n",
    "\n",
    "### Let's revist our prior example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c65ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example chain setup \n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "#chain 1 prompt and chain to output a city\n",
    "prompt1 = ChatPromptTemplate.from_template(\"Name a popular city for tourists to visit in {month}.\")\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "#chain 2 prompt and chain- uses city from prompt 1 to generate destinations \n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"What country is the {city} in? Name 3 popular tourist destinations in that country.\"\n",
    ")\n",
    "chain2 = (\n",
    "    {\"city\": chain1} #include chain 1! \n",
    "    | prompt2\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9dd1a5",
   "metadata": {},
   "source": [
    "### Let's invoke the chain with debug turned on\n",
    "\n",
    "Read through each line. \n",
    "#### Take note of: \n",
    "- What city did the model generate in chain 1? \n",
    "- What was passed to chain 2? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d32a1130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"month\": \"August\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<city>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"month\": \"August\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<city> > 3:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"month\": \"August\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<city> > 3:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"month\": \"August\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<city> > 3:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Name a popular city for tourists to visit in August.\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<city> > 3:chain:RunnableSequence > 5:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Name a popular city for tourists to visit in August.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<city> > 3:chain:RunnableSequence > 5:llm:ChatOpenAI] [939ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Paris, France\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Paris, France\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 3,\n",
      "      \"prompt_tokens\": 18,\n",
      "      \"total_tokens\": 21\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": \"fp_86156a94a0\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<city> > 3:chain:RunnableSequence > 6:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<city> > 3:chain:RunnableSequence > 6:parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Paris, France\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<city> > 3:chain:RunnableSequence] [942ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Paris, France\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<city>] [943ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"city\": \"Paris, France\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"city\": \"Paris, France\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"What country is the Paris, France in? Name 3 popular tourist destinations in that country.\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What country is the Paris, France in? Name 3 popular tourist destinations in that country.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:ChatOpenAI] [1.51s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Paris, France is in the country of France. \\n\\nThree popular tourist destinations in France are:\\n1. The Eiffel Tower in Paris\\n2. The Louvre Museum in Paris\\n3. The Palace of Versailles in Versailles, near Paris\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Paris, France is in the country of France. \\n\\nThree popular tourist destinations in France are:\\n1. The Eiffel Tower in Paris\\n2. The Louvre Museum in Paris\\n3. The Palace of Versailles in Versailles, near Paris\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 51,\n",
      "      \"prompt_tokens\": 26,\n",
      "      \"total_tokens\": 77\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": \"fp_86156a94a0\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Paris, France is in the country of France. \\n\\nThree popular tourist destinations in France are:\\n1. The Eiffel Tower in Paris\\n2. The Louvre Museum in Paris\\n3. The Palace of Versailles in Versailles, near Paris\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [2.46s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Paris, France is in the country of France. \\n\\nThree popular tourist destinations in France are:\\n1. The Eiffel Tower in Paris\\n2. The Louvre Museum in Paris\\n3. The Palace of Versailles in Versailles, near Paris\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Paris, France is in the country of France. \\n\\nThree popular tourist destinations in France are:\\n1. The Eiffel Tower in Paris\\n2. The Louvre Museum in Paris\\n3. The Palace of Versailles in Versailles, near Paris'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.globals import set_debug #import \n",
    "set_debug(True)\n",
    "chain2.invoke({\"month\": \"August\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32a15956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great! Now let's turn off debug for now...\n",
    "set_debug(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c74192",
   "metadata": {},
   "source": [
    "<a id='lab'></a>\n",
    "## Lab\n",
    "\n",
    "Build a series of 3 chains that 1) loads family preferences recommends a vacation destination, 2) it passes that vacation spot to a second model that recommends the best month to travel, 3) based on that month generates a 3-day travel itinerary. \n",
    "\n",
    "chain|chain type| input | output\n",
    "--|--|--| --|\n",
    "chain1 | create_stuff_documents_chain | family_docs | vacation destination \n",
    "chain2 | custom basic chain | vacation destination | month\n",
    "chain3 | custom basic chain | month | 3-day itinerary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc4aa8",
   "metadata": {},
   "source": [
    "#### Family Travel Documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "228c109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated by GPT\n",
    "family_docs = [\n",
    "    Document(page_content=\"Sarah likes to travel to warm places but not cold ones\"),\n",
    "    Document(page_content=\"John prefers cities with a rich history but doesn't like crowded places\"),\n",
    "    Document(page_content=\"Emma loves beach vacations but is not a fan of hiking\"),\n",
    "    Document(page_content=\"Mike enjoys adventurous trips but doesn't like long flights from Wales\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf1e96",
   "metadata": {},
   "source": [
    "#### Set Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "906a5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ca335",
   "metadata": {},
   "source": [
    "### Chain 1\n",
    "Use create_stuff_documents_chain to load family_docs and generate a vacation destination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "414fcd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb9a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build iteratively and test along the way "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f9df3d",
   "metadata": {},
   "source": [
    "### Chain 2\n",
    "Build a new chain to pass that vacation destination to a model generate the best month to travel to this location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6dc9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here!\n",
    "#chain 1 prompt and chain to output a city\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9038a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build iteratively and test along the way "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce0f08",
   "metadata": {},
   "source": [
    "### Chain 3\n",
    "Build a 3rd and final chain that generates a 3-day travel itinerary for the family "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6590bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c113f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build iteratively and test along the way \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ebec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676b509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
